{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "height": 65
   },
   "outputs": [],
   "source": [
    "# # Warning control\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../../api_keys.json\", mode = 'r') as f:\n",
    "    api_keys = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from utils import get_openai_api_key\n",
    "\n",
    "# openai_api_key = get_openai_api_key()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_keys['ashishjain1547'] \n",
    "os.environ[\"MODEL\"] = \"gemini/gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "litellm.api_key = api_keys['ashishjain1547']  # Ensure this is set\n",
    "litellm.model = \"gemini/gemini-2.0-flash\"  # Ensure Gemini is being used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agents\n",
    "\n",
    "- Define your Agents, and provide them a `role`, `goal` and `backstory`.\n",
    "- It has been seen that LLMs perform better when they are role playing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "height": 235
   },
   "outputs": [],
   "source": [
    "grammar_expert = Agent(\n",
    "    role=\"Hindi-English Grammar Expert\",\n",
    "    goal=\"Evaluate a Hindi-English sentence pair for grammatical correctness.\"\n",
    "    \"Hindi: {hindi}\\nEnglish: {english}\",\n",
    "    backstory=\"You're working on a language learning app for novice English learner who are fluent in Hindi.\"\n",
    "              \"You evaluate sentences for grammatical correctness.\"\n",
    "              \"You return your answer as 0 if sentence pair are grammatically incorrect and 1 if sentence pair are grammatically correct.\"\n",
    "              \"You give 0 also in the case if either English or Hindi sentence alone is grammatically incorrect.\",\n",
    "    allow_delegation=False,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "height": 371
   },
   "outputs": [],
   "source": [
    "profanity_checker = Agent(\n",
    "    role=\"Profanity Checker\",\n",
    "    goal=\"Evaluate a Hindi-English sentence pair for profanity\"\n",
    "    \"Hindi: {hindi}\\nEnglish: {english}\",\n",
    "    backstory=\"You're working on a language learning app for novice English learner who are fluent in Hindi.\"\n",
    "    \"You evaluate sentences for profanity.\"\n",
    "    \"If the sentence (or both sentences) are double meaning, directly or indirectly vulgar, or contain profanity, you return 0.\"\n",
    "    \"Otherwise, you return 1.\",\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tasks\n",
    "\n",
    "- Define your Tasks, and provide them a `description`, `expected_output` and `agent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "height": 269
   },
   "outputs": [],
   "source": [
    "check_grammar = Task(\n",
    "    description=(\n",
    "        \"1. Check the grammar of the Hindi sentence.\\n\"\n",
    "        \"2. Check the grammar of the English sentence.\\n\"\n",
    "        \"3. Check that Hindi-English sentence pair mean the same thing.\"\n",
    "    ),\n",
    "    expected_output=\"0 if grammar is incorrect, and 1 if grammar is correct\",\n",
    "    agent=grammar_expert\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "height": 320
   },
   "outputs": [],
   "source": [
    "profanity_check = Task(\n",
    "    description=(\n",
    "        \"1. Check the Hindi sentence for profanity, vulgarness or double meaning.\\n\"\n",
    "        \"2. Check the English sentence for profanity, vulgarness or double meaning.\"\n",
    "    ),\n",
    "    expected_output=\"0 if profanity is there, and 1 if profanity is NOT there\",\n",
    "    agent=profanity_checker\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Crew\n",
    "\n",
    "- Create your crew of Agents\n",
    "- Pass the tasks to be performed by those agents.\n",
    "    - **Note**: *For this simple example*, the tasks will be performed sequentially (i.e they are dependent on each other), so the _order_ of the task in the list _matters_.\n",
    "- `verbose=2` allows you to see all the logs of the execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "height": 99
   },
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[grammar_expert, profanity_checker],\n",
    "    tasks=[check_grammar, profanity_check],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: LLMs can provide different outputs for they same input, so what you get might be different than what you see in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:12][üöÄ CREW 'CREW' STARTED, 9DF17E85-39E2-4958-876A-BDB3201F8447]: 2025-03-13 20:34:12.712794\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:12][üìã TASK STARTED: 1. CHECK THE GRAMMAR OF THE HINDI SENTENCE.\n",
      "2. CHECK THE GRAMMAR OF THE ENGLISH SENTENCE.\n",
      "3. CHECK THAT HINDI-ENGLISH SENTENCE PAIR MEAN THE SAME THING.]: 2025-03-13 20:34:12.733530\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:12][ü§ñ AGENT 'HINDI-ENGLISH GRAMMAR EXPERT' STARTED TASK]: 2025-03-13 20:34:12.735223\u001b[00m\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mHindi-English Grammar Expert\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Check the grammar of the Hindi sentence.\n",
      "2. Check the grammar of the English sentence.\n",
      "3. Check that Hindi-English sentence pair mean the same thing.\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:12][ü§ñ LLM CALL STARTED]: 2025-03-13 20:34:12.735502\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:15][‚úÖ LLM CALL COMPLETED]: 2025-03-13 20:34:15.229963\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mHindi-English Grammar Expert\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "0\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:15][‚úÖ AGENT 'HINDI-ENGLISH GRAMMAR EXPERT' COMPLETED TASK]: 2025-03-13 20:34:15.231743\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:15][‚úÖ TASK COMPLETED: 1. CHECK THE GRAMMAR OF THE HINDI SENTENCE.\n",
      "2. CHECK THE GRAMMAR OF THE ENGLISH SENTENCE.\n",
      "3. CHECK THAT HINDI-ENGLISH SENTENCE PAIR MEAN THE SAME THING.]: 2025-03-13 20:34:15.232011\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:15][üìã TASK STARTED: 1. CHECK THE HINDI SENTENCE FOR PROFANITY, VULGARNESS OR DOUBLE MEANING.\n",
      "2. CHECK THE ENGLISH SENTENCE FOR PROFANITY, VULGARNESS OR DOUBLE MEANING.]: 2025-03-13 20:34:15.245063\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:15][ü§ñ AGENT 'PROFANITY CHECKER' STARTED TASK]: 2025-03-13 20:34:15.249285\u001b[00m\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProfanity Checker\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Check the Hindi sentence for profanity, vulgarness or double meaning.\n",
      "2. Check the English sentence for profanity, vulgarness or double meaning.\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:15][ü§ñ LLM CALL STARTED]: 2025-03-13 20:34:15.249421\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:17][‚úÖ LLM CALL COMPLETED]: 2025-03-13 20:34:17.458551\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProfanity Checker\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "1\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:17][‚úÖ AGENT 'PROFANITY CHECKER' COMPLETED TASK]: 2025-03-13 20:34:17.460147\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:17][‚úÖ TASK COMPLETED: 1. CHECK THE HINDI SENTENCE FOR PROFANITY, VULGARNESS OR DOUBLE MEANING.\n",
      "2. CHECK THE ENGLISH SENTENCE FOR PROFANITY, VULGARNESS OR DOUBLE MEANING.]: 2025-03-13 20:34:17.460455\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 20:34:17][‚úÖ CREW 'CREW' COMPLETED, 9DF17E85-39E2-4958-876A-BDB3201F8447]: 2025-03-13 20:34:17.470015\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "result = crew.kickoff(inputs={\"hindi\": \"‡§Æ‡•à‡§Ç ‡§¶‡•Ç‡§ß ‡§π‡•Ç‡§Å\", \"english\": \"I am milk\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the results of your execution as markdown in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "height": 48
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Hindi-English Grammar Expert\n",
      "Description: 1. Check the grammar of the Hindi sentence.\n",
      "2. Check the grammar of the English sentence.\n",
      "3. Check that Hindi-English sentence pair mean the same thing.\n",
      "Expected Output: 0 if grammar is incorrect, and 1 if grammar is correct\n",
      "Task Result: 0\n",
      "\n",
      "Agent: Profanity Checker\n",
      "Description: 1. Check the Hindi sentence for profanity, vulgarness or double meaning.\n",
      "2. Check the English sentence for profanity, vulgarness or double meaning.\n",
      "Expected Output: 0 if profanity is there, and 1 if profanity is NOT there\n",
      "Task Result: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for task in result.tasks_output:\n",
    "    print(f\"Agent: {task.agent}\")\n",
    "    print(f\"Description: {task.description}\")\n",
    "    print(f\"Expected Output: {task.expected_output}\")\n",
    "    print(f\"Task Result: {task.raw}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "crewai_2025",
   "language": "python",
   "name": "crewai_2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
